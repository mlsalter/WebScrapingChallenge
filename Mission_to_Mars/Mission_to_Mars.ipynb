{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://splinter.readthedocs.io/en/latest/drivers/chrome.html\n",
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "#adding in splinter needed item\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "response = browser.html\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = bs(response, 'html.parser')\n",
    "# Examine the results, then determine element that contains sought info\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results are returned as an iterable list\n",
    "results = soup.find_all('div', class_=\"content_title\")\n",
    "for r in results:\n",
    "#    print(r.prettify())\n",
    "    print(r.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save first tag title and paragraph to variables (use select_one to only pull first in the list)\n",
    "element = soup.select_one('ul.item_list li.slide')\n",
    "\n",
    "news_title = element.find(\"div\", class_='content_title').get_text()\n",
    "news_para = element.find(\"div\", class_='article_teaser_body').get_text()\n",
    "\n",
    "print(news_title)\n",
    "print(news_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featured Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "#adding in splinter needed item\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to click on full image for the large size jpg image\n",
    "browser.find_by_id('full_image').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click on more info button\n",
    "browser.is_element_present_by_text('more info', wait_time=1)\n",
    "browser.find_link_by_partial_text('more info').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "i_soup = bs(html, 'html.parser')\n",
    "# Examine the results, then determine element that contains sought info\n",
    "print(i_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the .jpg url and create a full url\n",
    "partial_image_url = i_soup.select_one('figure.lede a').get('href')\n",
    "\n",
    "image_url = f'https://www.jpl.nasa.gov{partial_image_url}'\n",
    "image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "#adding in splinter needed item\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "w_soup = bs(html, 'html.parser')\n",
    "# Examine the results, then determine element that contains sought info\n",
    "print(w_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the latest Mars weather tweet\n",
    "weather_tweet = w_soup.find('div', attrs={\"class\": \"tweet\", \"data-name\": \"Mars Weather\"})\n",
    "#print(weather_tweet)\n",
    "\n",
    "#Save the text as variable mars_weather\n",
    "mars_weather = weather_tweet.find('p', 'js-tweet-text').text\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place mars facts into dataframe\n",
    "facts_df = pd.read_html('https://space-facts.com/mars/')[0]\n",
    "facts_df.columns=['Description', 'Value']\n",
    "facts_df.set_index('Description', inplace=True)\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe to html\n",
    "facts_df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## URL of page to be scraped\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "#adding in splinter needed item\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "f_soup = bs(html, 'html.parser')\n",
    "# Examine the results, then determine element that contains sought info\n",
    "print(f_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hem_image_urls = []\n",
    "\n",
    "# List of all of the hemispheres\n",
    "hem_links = browser.find_by_css(\"a.product-item h3\")\n",
    "\n",
    "# Loop through to return the image up for each\n",
    "for r in range(4):\n",
    "    \n",
    "    browser.find_by_css(\"a.product-item h3\")[r].click()\n",
    "    \n",
    "    sample = browser.find_link_by_text('Sample').first\n",
    "    url= sample['href']\n",
    "    \n",
    "    title= browser.find_by_css(\"h2.title\").text\n",
    "    \n",
    "    #place info into dictionary  \n",
    "    hem_image_url.append({'Image URL': url, 'Title':title})\n",
    "    \n",
    "    \n",
    "    #Now we need to go back to the main page\n",
    "    browser.back()\n",
    "print(hem_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
